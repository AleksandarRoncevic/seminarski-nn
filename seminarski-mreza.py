# -*- coding: utf-8 -*-
"""kernel40d2a72249.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1oOF1gbGXaXyJw1_ha3QipswvxqUqFBhi
"""

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
import glob
import os
import cv2
import keras
X = []
Y = []


#for dirname, _, filenames in os.walk('/content/images.tar'):
#    for filename in filenames:
#        path = os.path.join(dirname, filename)
        # if("without_mask" in path): #promeniti uslov ya path
        #     resized = cv2.resize(cv2.imread(path), (64,64)) #resize?
        #     X.append(resized)
        #     Y.append(0)
        # else:
        #     resized = cv2.resize(cv2.imread(path), (64,64))
        #     X.append(resized)
        #     Y.append(1)
#krsma comment
#LINK = ""

PATH = "/content/drive/My Drive/maskData/*/*"
# test = glob.glob(PATH)
# int(test[0].split('/')[5]=="yesMask")
for x in glob.glob(PATH):
      X.append(cv2.imread(x)) #No resize, 150x150 is consdietd
      Y.append(int(x.split('/')[5]=="yesMask"))
Y[:10]
Y[len(Y)-10:]

from google.colab import drive
drive.mount('/content/drive')

from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test = train_test_split(X,Y,test_size = 0.2)
len(X_train)
len(X_test)
# podela data seta na treniranje i test

X_train = np.asarray(X_train)
X_test = np.asarray(X_test)
y_train = np.asarray(y_train)
y_test = np.asarray(y_test)

from keras.models import Sequential
from keras.layers import Conv2D,MaxPooling2D,AveragePooling2D,Dense,Flatten,Dropout
from keras.optimizers import Adam

INPUT_SHAPE = 128
cnn = Sequential()
#1. layer
cnn.add(Conv2D(filters = 32, kernel_size =(3,3), 
               activation = 'relu',input_shape = (INPUT_SHAPE,INPUT_SHAPE,3)))
#2. layer
cnn.add(Conv2D(filters = 32, kernel_size =(3,3), 
               activation = 'relu'))
cnn.add(MaxPooling2D(2,2))
cnn.add(Dropout(0.3))
#3. layer
cnn.add(Conv2D(filters = 64, kernel_size =(3,3), activation = 'relu'))
#4. layer
cnn.add(Conv2D(filters = 64, kernel_size =(3,3), 
               activation = 'relu'))
cnn.add(MaxPooling2D(2,2))
cnn.add(Dropout(0.2))

cnn.add(Flatten())

cnn.add(Dense(units = 512, activation = 'relu'))
cnn.add(Dense(units = 512, activation = 'relu'))
cnn.add(Dense(units = 1, activation = 'sigmoid'))

cnn.compile(loss = 'binary_crossentropy',
            optimizer = 'adam',
            metrics = ['accuracy'])

#def reshape_data(input_data):
#    nsamples, nx, ny = input_data.shape
#    return input_data.reshape((nsamples, nx*ny))

X_train = X_train/255
X_test = X_test/255

from sklearn.utils import shuffle
X_train, y_train = shuffle(X_train, y_train)

hist = cnn.fit(X_train,y_train,epochs = 10,batch_size = 128,verbose = 1, validation_split = 0.2)

pred = cnn.predict(X_test)

pred[pred>0.5]=1
pred[pred!=1]=0

from sklearn.metrics import confusion_matrix
cm = confusion_matrix(y_test,pred)
cm

from sklearn.metrics import f1_score
score=f1_score(y_test, pred, average='macro')
score